{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from models import Generator, predict_many, predict_one\n",
    "from data import load_data_from_pickle, translate, load_dataset, dump_txt_to_pickle\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#print(torch.cuda.get_device_name(), \"|\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"Data/dubsmash_processed.txt\"\n",
    "# dataset_name = \"dubsmash\"\n",
    "\n",
    "# t = datetime.datetime.now()\n",
    "# filtered_lines, charmap, inv_charmap = load_dataset(path)\n",
    "# dump_txt_to_pickle(path, dataset_name, test_size=0.1)\n",
    "# print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.770379\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"dubsmash\"\n",
    "t = datetime.datetime.now()\n",
    "test_data, charmap, inv_charmap = load_data_from_pickle(dataset_name, train_data=False, test_data=True)\n",
    "print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_data = pd.Series(translate(test_data, inv_charmap))\n",
    "test_data = orig_test_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650695, 95)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data), len(charmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Latest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (lin): Linear(in_features=128, out_features=1280, bias=True)\n",
       "  (block1): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (block2): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (block3): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (block4): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (block5): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (conv): Conv1d(128, 95, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = Generator(charmap).to(device)\n",
    "netG.load_state_dict(torch.load(\"Checkpoints/netG-15800002:26:12PM_12-05-20\", map_location=torch.device(device)))\n",
    "netG.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Passwords from Latest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100000\n",
    "batches_per_file = 100\n",
    "num_files = 100\n",
    "\n",
    "print(f\"Generating {batch_size * batches_per_file * num_files} passwords...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(netG, inv_charmap, batches_per_file, num_files, batch_size=100000):\n",
    "    print(f\"Generating {batch_size * batches_per_file * num_files} passwords...\")\n",
    "    t_total = datetime.datetime.now()\n",
    "    for i in range(1, num_files+1):\n",
    "        t = datetime.datetime.now()\n",
    "        print(f\"File {i}\")\n",
    "        print(\"\\tGenerating output...\")\n",
    "        preds = []\n",
    "        for _ in range(batches_per_file):\n",
    "            preds.append(netG(torch.randn(batch_size, 128).to(device=device)).argmax(dim=2)) #max 100k fits in memory\n",
    "        list_of_preds = torch.stack(preds).reshape((-1, 10)).cpu().tolist()\n",
    "        del preds\n",
    "        print(\"\\tTranslating output...\")\n",
    "        translated_preds = translate(list_of_preds, inv_charmap)\n",
    "\n",
    "        del list_of_preds\n",
    "        print(\"\\tWriting output...\")\n",
    "        with open(f\"Predictions/predfile_{i}_{batch_size*batches_per_file}.txt\", 'w+') as f:\n",
    "            for pred in translated_preds:\n",
    "                f.write(pred + \"\\n\")\n",
    "        print(f\"\\t{datetime.datetime.now() - t}\")\n",
    "        del translated_preds\n",
    "    print(f\"\\tTotal: {datetime.datetime.now() - t_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1000000000 passwords...\n"
     ]
    }
   ],
   "source": [
    "write_predictions(netG, inv_charmap, batches_per_file, num_files, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 Predictions/predfile_1_10000000.txt\n",
      "total 11G\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 04:00 predfile_100_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:49 predfile_10_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:50 predfile_11_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:52 predfile_12_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:53 predfile_13_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:55 predfile_14_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:56 predfile_15_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:58 predfile_16_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:59 predfile_17_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:01 predfile_18_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:02 predfile_19_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:35 predfile_1_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:04 predfile_20_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:05 predfile_21_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:06 predfile_22_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:08 predfile_23_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:09 predfile_24_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:11 predfile_25_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:12 predfile_26_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:14 predfile_27_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:15 predfile_28_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:17 predfile_29_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:37 predfile_2_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:18 predfile_30_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:19 predfile_31_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:21 predfile_32_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:22 predfile_33_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:24 predfile_34_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:25 predfile_35_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:27 predfile_36_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:28 predfile_37_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:30 predfile_38_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:31 predfile_39_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:38 predfile_3_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:33 predfile_40_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:34 predfile_41_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:35 predfile_42_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:37 predfile_43_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:38 predfile_44_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:40 predfile_45_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:41 predfile_46_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:43 predfile_47_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:44 predfile_48_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:46 predfile_49_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:40 predfile_4_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:47 predfile_50_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:49 predfile_51_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:50 predfile_52_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:52 predfile_53_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:53 predfile_54_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:54 predfile_55_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:56 predfile_56_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:57 predfile_57_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 02:59 predfile_58_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:00 predfile_59_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:41 predfile_5_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:02 predfile_60_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:03 predfile_61_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:05 predfile_62_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:06 predfile_63_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:07 predfile_64_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:09 predfile_65_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:10 predfile_66_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:12 predfile_67_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:13 predfile_68_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:15 predfile_69_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:43 predfile_6_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:16 predfile_70_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:18 predfile_71_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:19 predfile_72_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:21 predfile_73_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:22 predfile_74_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:23 predfile_75_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:25 predfile_76_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:26 predfile_77_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:28 predfile_78_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:29 predfile_79_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:44 predfile_7_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:31 predfile_80_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:32 predfile_81_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:34 predfile_82_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:35 predfile_83_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:37 predfile_84_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:38 predfile_85_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:39 predfile_86_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:41 predfile_87_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:42 predfile_88_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:44 predfile_89_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:46 predfile_8_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:45 predfile_90_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:47 predfile_91_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:48 predfile_92_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:50 predfile_93_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:51 predfile_94_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:53 predfile_95_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:54 predfile_96_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:55 predfile_97_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:57 predfile_98_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 03:58 predfile_99_10000000.txt\n",
      "-rw-rw-r-- 1 nvijayakumar nvijayakumar 105M Dec  6 01:47 predfile_9_10000000.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l Predictions/predfile_1_10000000.txt # 10million = 105MB\n",
    "!ls -lh Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples from various checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions from Various Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_to_predict = OrderedDict()\n",
    "checkpoints_to_predict['1'] = \"Checkpoints/netG-101:32:11AM_12-04-20\"\n",
    "checkpoints_to_predict['5000'] = \"Checkpoints/netG-500002:41:42AM_12-04-20\"\n",
    "checkpoints_to_predict['10000'] = \"Checkpoints/netG-1000003:50:37AM_12-04-20\"\n",
    "checkpoints_to_predict['25000'] = \"Checkpoints/netG-2500007:19:11AM_12-04-20\"\n",
    "checkpoints_to_predict['75000'] = \"Checkpoints/netG-7500006:46:08PM_12-04-20\"\n",
    "checkpoints_to_predict['158000'] = \"Checkpoints/netG-15800002:26:12PM_12-05-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint iterations 1: \t ['EbApeY>bK=', 'A[;OFq!ajK', \"Pb(d7unk'qtP\", '..}&}c05np', 'k!=G a.YCz']\n",
      "Checkpoint iterations 5000: \t ['howoriy8||', 'ilintnlo||', 'cortoe2345', '12brrtto||', 'samirta|||']\n",
      "Checkpoint iterations 10000: \t ['auman!||||', 'variane|||', 'bebrw6133|', 'awerebyw9|', 'fanrarg12|']\n",
      "Checkpoint iterations 25000: \t ['blericas||', 'Wapererah|', 'allafosty|', '12345|||||', 'sikcrisho|']\n",
      "Checkpoint iterations 75000: \t ['041515bo||', 'jamera||||', 'simsah1|||', 'carny}20||', 'danithi2||']\n",
      "Checkpoint iterations 158000: \t ['l3048806||', 'towe170509', 'camrrsa|||', '12345|||||', '00301|||||']\n"
     ]
    }
   ],
   "source": [
    "for key, value in checkpoints_to_predict.items():\n",
    "    netG = Generator(charmap).to(device)\n",
    "    netG.load_state_dict(torch.load(value))\n",
    "    print(f\"Checkpoint iterations {key}: \\t {predict_one(netG, inv_charmap, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Results and Analysis via Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:55941</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:55941' processes=4 threads=12, memory=17.18 GB>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000000\n",
      "0:02:07.150311\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=200</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 200 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                Passwords\n",
       "npartitions=200          \n",
       "                   object\n",
       "                      ...\n",
       "...                   ...\n",
       "                      ...\n",
       "                      ...\n",
       "Dask Name: read-csv, 200 tasks"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = datetime.datetime.now()\n",
    "predictions = dd.read_table(\"Predictions/predfile_*_10000000.txt\", names=[\"Passwords\"]) #reads all generated passwords\n",
    "print(len(predictions))\n",
    "print(datetime.datetime.now() - t)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.001887\n",
      "0:00:00.141336\n",
      "0:00:00.000258\n"
     ]
    }
   ],
   "source": [
    "t = datetime.datetime.now()\n",
    "unique_predictions = predictions['Passwords'].drop_duplicates()\n",
    "print(datetime.datetime.now() - t)\n",
    "t = datetime.datetime.now()\n",
    "preds_mask = unique_predictions.isin(test_data)\n",
    "print(datetime.datetime.now() - t)\n",
    "t = datetime.datetime.now()\n",
    "matched_preds = unique_predictions[preds_mask]\n",
    "print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b3efb5dac404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_unique_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         return self.reduction(\n\u001b[0m\u001b[1;32m    536\u001b[0m             \u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"len\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         ).compute()\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2723\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2726\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   1987\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t = datetime.datetime.now()\n",
    "num_unique_generated = len(unique_predictions)\n",
    "print(datetime.datetime.now() - t)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "unmatched_generated_pws = unique_predictions[~preds_mask].sample(frac=0.0001).compute()\n",
    "print(datetime.datetime.now() - t)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "matched_passwords = matched_preds.compute()\n",
    "print(datetime.datetime.now() - t)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "test_matched_mask = orig_test_data.isin(matched_passwords)\n",
    "print(datetime.datetime.now() - t)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "proportion_in_unique_predictions_that_matched = preds_mask.mean().compute()\n",
    "print(datetime.datetime.now() - t)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "proportion_of_test_set_that_matched = orig_test_data.isin(matched_passwords).mean()\n",
    "print(datetime.datetime.now() - t)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "proportion_that_was_uniquely_generated = num_unique_generated/len(predictions)\n",
    "print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample of Matched Passwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_passwords.str.replace(\"|\", \"\").to_list()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proportion of unique predictions generated that matched with a password in the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_in_unique_predictions_that_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proportion of test set whose passwords were found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_of_test_set_that_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of unique passwords that were generated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proportion of generated passwords that are unique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_that_was_uniquely_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample of unmatched generated passwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_generated_pws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample of unmatched test set passwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_data[~test_matched_mask].iloc[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative to Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "please_work = pd.read_fwf(\"Predictions/predfile_1_10000000.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:07.678020\n"
     ]
    }
   ],
   "source": [
    "t = datetime.datetime.now()\n",
    "please_work = pd.read_table(\"Predictions/predfile_1_10000000.txt\", names=[\"Password\"])['Password'].drop_duplicates()\n",
    "print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340648125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "please_work.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.340648125"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "340648125/1000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:54929</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:54929' processes=4 threads=12, memory=17.18 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Passwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=200</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 200 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                Passwords\n",
       "npartitions=200          \n",
       "                   object\n",
       "                      ...\n",
       "...                   ...\n",
       "                      ...\n",
       "                      ...\n",
       "Dask Name: read-csv, 200 tasks"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = dd.read_table(\"Predictions/predfile_*_10000000.txt\", names=[\"Passwords\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-75baf91cd97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplease_work\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2723\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2726\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   1987\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/pytorch-env/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "please_work = predictions.drop_duplicates().sample(frac=0.0001).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45420, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "please_work.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
