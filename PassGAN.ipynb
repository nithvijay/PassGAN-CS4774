{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PassGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla T4 | True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from models import Generator, write_predictions, predict_many, predict_one\n",
    "from data import load_dataset, dump_txt_to_pickle, load_data_from_pickle, dataloader, translate\n",
    "from training import training_loop\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.cuda.get_device_name(), \"|\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:23.054754\n"
     ]
    }
   ],
   "source": [
    "path = \"Data/dubsmash_processed.txt\"\n",
    "dataset_name = \"dubsmash\"\n",
    "\n",
    "# filtered_lines, charmap, inv_charmap = load_dataset(path)\n",
    "# dump_txt_to_pickle(path, dataset_name, test_size=0.1)\n",
    "\n",
    "t = datetime.datetime.now()\n",
    "train_lines, test_lines, charmap, inv_charmap = load_data_from_pickle(dataset_name, test_data=True)\n",
    "print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Size:\t19458235\n",
      "Testing Size:\t1024117\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTraining Size:\\t{len(train_lines):>7}\\nTesting Size:\\t{len(test_lines):>7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12345|||||',\n",
       " '12345|||||',\n",
       " 'anthony11|',\n",
       " 'maverick||',\n",
       " 'linda|||||',\n",
       " 'stonekids|',\n",
       " 'diamond|||',\n",
       " '123456789|']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataloader(train_lines, 8)\n",
    "translate(next(train), inv_charmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "Function parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded, starting at 2000...\n",
      "iterations 2000\n",
      "\tFake: ['luvis|||||', 'sRacagid||', '12345|||||', '12306|||||', '12345||8u|', 'logbetee||', 'cerl||||||', 'frin1|3|||', 'arenee8|||', 'PeeMas8|||']\n",
      "\tReal: ['starxxx|||', '123456789|', '123456789|', 'apogeu2014', '12345|||||', 'magic|||||', 'single||||', 'iloveyou||', '12345|||||', '123456789|']\n",
      "iterations 3000\n",
      "\tFake: ['lelis034||', 'lelolie|||', 'Meolio2|||', 'lalletli||', '123456||||', '12045123||', 'fogeulacad', 'lelol|||||', 'janha|||||', 'fo30006|||']\n",
      "\tReal: ['zxcvbnm|||', 'rebecca|||', 'Twerking1|', 'asdfg|||||', 'Lorella|||', '189841||||', 'qwerty12||', '12345|||||', 'forti123||', 'shahid||||']\n"
     ]
    }
   ],
   "source": [
    "lines = train_lines\n",
    "dataloader = dataloader #function from data.py\n",
    "\n",
    "args = {}\n",
    "args['lambda_'] = 10\n",
    "args['n_critic_iters_per_generator_iter'] = 10\n",
    "args['batch_size'] = 128\n",
    "args['lr'] = 1e-4\n",
    "args['adam_beta1'] = 0.5\n",
    "args['adam_beta2'] = 0.9\n",
    "args['iterations'] = 3000\n",
    "args['continue_training'] = True\n",
    "args['netG_checkpoint'] = \"Checkpoints/netG-200002:00:07AM_12-04-20\"\n",
    "args['netD_checkpoint'] = \"Checkpoints/netD-200002:00:07AM_12-04-20\"\n",
    "\n",
    "training_loop(lines, charmap, inv_charmap, dataloader, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05.219250\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"dubsmash\"\n",
    "t = datetime.datetime.now()\n",
    "test_data, charmap, inv_charmap = load_data_from_pickle(dataset_name, train_data=False, test_data=True)\n",
    "print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (lin): Linear(in_features=128, out_features=1280, bias=True)\n",
       "  (block1): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (block2): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (block3): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (block4): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (block5): ResidualBlock(\n",
       "    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (conv): Conv1d(128, 95, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = Generator(charmap).to(device)\n",
    "netG.load_state_dict(torch.load(\"Checkpoints/netG-15800002:26:12PM_12-05-20\", map_location=torch.device(device))) # latest model\n",
    "netG.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100000 passwords...\n",
      "File 1\n",
      "\tGenerating output...\n",
      "\tTranslating output...\n",
      "\tWriting output...\n",
      "\t0:00:00.965810\n",
      "\tTotal: 0:00:00.967292\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100000\n",
    "batches_per_file = 1\n",
    "num_files = 1\n",
    "\n",
    "write_predictions(netG, inv_charmap, batches_per_file, num_files, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Predictions Work\n",
    "\n",
    "Samples the latent space\n",
    "```python\n",
    "latent_noise = torch.randn(batch_size, 128).to(device=device)\n",
    "```\n",
    "\n",
    "Produces vectors of probabilities for each class for each character\n",
    "```python\n",
    "pred = netG(latent_noise)\n",
    "```\n",
    "\n",
    "Find the character with the highest probability for each character and translate numeric to character\n",
    "```python\n",
    "translated_pred = translate(pred.argmax(dim=2), inv_charmap)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kratty||||', 'Bhodssbers', 'bliTnar73|', 'kelgar||||']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "latent_noise = torch.randn(batch_size, 128).to(device=device)\n",
    "pred = netG(latent_noise)\n",
    "translated_pred = translate(pred.argmax(dim=2), inv_charmap)\n",
    "translated_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions Across Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_to_predict = OrderedDict()\n",
    "checkpoints_to_predict['1'] = \"Checkpoints/netG-101:32:11AM_12-04-20\"\n",
    "checkpoints_to_predict['1000'] = 'Checkpoints/netG-100001:46:05AM_12-04-20'\n",
    "checkpoints_to_predict['5000'] = \"Checkpoints/netG-500002:41:42AM_12-04-20\"\n",
    "checkpoints_to_predict['10000'] = \"Checkpoints/netG-1000003:50:37AM_12-04-20\"\n",
    "checkpoints_to_predict['25000'] = \"Checkpoints/netG-2500007:19:11AM_12-04-20\"\n",
    "checkpoints_to_predict['75000'] = \"Checkpoints/netG-7500006:46:08PM_12-04-20\"\n",
    "checkpoints_to_predict['158000'] = \"Checkpoints/netG-15800002:26:12PM_12-05-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint iterations      1: \t ['{Y6z#}7oK@', 'OsFz\"t9qpz', \"l&qO='P@%@\", '/?5\"5.p3&!', '%dgF@]-nV0']\n",
      "Checkpoint iterations   1000: \t ['pbsrin12||', '12345||46|', 'hocelute||', 'knemaran||', 'kamemino||']\n",
      "Checkpoint iterations   5000: \t ['sypriZy8||', '12345|||||', '12345|||||', 'ceslole|||', 'aria2100||']\n",
      "Checkpoint iterations  10000: \t ['gienreal||', '13345678om', 'keugiss|||', '50026a||||', 'vinan|||||']\n",
      "Checkpoint iterations  25000: \t ['12345|||||', '102000||||', 'ranarn77||', 'tipper||||', '12345|||||']\n",
      "Checkpoint iterations  75000: \t ['1451a1uz$@', 'nagaka||||', '515229|0||', 'adtcyozu||', 'monaoal4||']\n",
      "Checkpoint iterations 158000: \t ['bayamary||', '262S14d2||', 'spuareanaa', 'fylier||||', 'dangy8868|']\n"
     ]
    }
   ],
   "source": [
    "for key, value in checkpoints_to_predict.items():\n",
    "    netG = Generator(charmap).to(device)\n",
    "    netG.load_state_dict(torch.load(value, map_location=torch.device(device)))\n",
    "    print(f\"Checkpoint iterations {key:>6}: \\t {predict_one(netG, inv_charmap, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:49.351868\n"
     ]
    }
   ],
   "source": [
    "pred_paths = glob.glob(\"Predictions/predfile_*_10000000.txt\")\n",
    "t = datetime.datetime.now()\n",
    "list_of_dfs = [pd.read_table(path, names=[\"Password\"]) for path in pred_paths]\n",
    "predictions = pd.concat(list_of_dfs, axis=0, ignore_index=True)\n",
    "print(datetime.datetime.now() - t)\n",
    "\n",
    "orig_test_data = pd.Series(translate(test_data, inv_charmap))\n",
    "test_data = orig_test_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Password</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obeve797||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rinline1||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woley14|||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12345|||||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12345|||||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999995</th>\n",
       "      <td>buepyr||||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999996</th>\n",
       "      <td>almbers|||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999997</th>\n",
       "      <td>12345|||||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999998</th>\n",
       "      <td>041010||||</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999999</th>\n",
       "      <td>12345|||||</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Password\n",
       "0          obeve797||\n",
       "1          rinline1||\n",
       "2          woley14|||\n",
       "3          12345|||||\n",
       "4          12345|||||\n",
       "...               ...\n",
       "999999995  buepyr||||\n",
       "999999996  almbers|||\n",
       "999999997  12345|||||\n",
       "999999998  041010||||\n",
       "999999999  12345|||||\n",
       "\n",
       "[1000000000 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:08:59.285089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            obeve797||\n",
       "1            rinline1||\n",
       "2            woley14|||\n",
       "3            12345|||||\n",
       "5            blar||||||\n",
       "                ...    \n",
       "999999955    tirian20||\n",
       "999999973    taywl2s14|\n",
       "999999975    makimuraty\n",
       "999999978    moobovass|\n",
       "999999983    marenebaR|\n",
       "Name: Password, Length: 163341589, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = datetime.datetime.now()\n",
    "unique_predictions = predictions['Password'].drop_duplicates()\n",
    "print(datetime.datetime.now() - t)\n",
    "unique_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          123456789|\n",
       "1          09090909||\n",
       "2          naveen||||\n",
       "3          jerry|||||\n",
       "4          jultomten|\n",
       "              ...    \n",
       "1024107    malakhai15\n",
       "1024108    alejo17|||\n",
       "1024111    91gosane||\n",
       "1024115    Lilybug5||\n",
       "1024116    drpepper22\n",
       "Length: 346442, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:53.845038\n"
     ]
    }
   ],
   "source": [
    "t = datetime.datetime.now()\n",
    "preds_mask = unique_predictions.isin(test_data)\n",
    "matched_preds = unique_predictions[preds_mask]\n",
    "num_unique_generated = len(unique_predictions)\n",
    "unmatched_generated_pws = unique_predictions[~preds_mask].sample(n=100)\n",
    "test_matched_mask = orig_test_data.isin(matched_preds)\n",
    "proportion_in_unique_predictions_that_matched = preds_mask.mean()\n",
    "proportion_of_test_set_that_matched = test_matched_mask.mean()\n",
    "proportion_of_deduped_test_set_that_matched = test_data.isin(matched_preds).mean()\n",
    "proportion_that_was_uniquely_generated = num_unique_generated/len(predictions)\n",
    "print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample of Matched Passwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58875845       tabatha\n",
       "11933552     jeanna123\n",
       "332354153     colorama\n",
       "848881        sammy123\n",
       "4562238         033089\n",
       "490386357      monavie\n",
       "2804297         080701\n",
       "137613699       minna1\n",
       "307375209     smiles94\n",
       "537571507      hosanna\n",
       "Name: Password, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_preds.str.replace(\"|\", \"\").sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proportion of unique predictions generated that matched with a password in the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020288770424536521"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_in_unique_predictions_that_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proportion of test set whose passwords were found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47678341439503497"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_of_test_set_that_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proportion of deduped test set whose passwords were found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09565814768417225"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_of_deduped_test_set_that_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of unique passwords that were generated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163341589"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proportion of generated passwords that are unique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.163341589"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_that_was_uniquely_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample of unmatched generated passwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354672284    zowera422+\n",
       "638797419    Bujisnne7|\n",
       "174714066    huntackes|\n",
       "779687666    bunthuniay\n",
       "530405511    kitaSB4227\n",
       "914627515    79698rut||\n",
       "35407215     0987701982\n",
       "539553617    wlimashaci\n",
       "119192500    anesuer27|\n",
       "36400773     Smlza|||||\n",
       "Name: Password, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_generated_pws.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample of unmatched test set passwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164835     Justine09|\n",
       "231796     fffff|||||\n",
       "36872      akki14126|\n",
       "1005472    pretty||||\n",
       "295361     iloveyou2|\n",
       "767123     juventus||\n",
       "169212     br3lici0us\n",
       "847852     Bunny1234|\n",
       "636238     iloveyou09\n",
       "365803     hockey22||\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_test_data[~test_matched_mask].sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rockyou**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Data/rockyou_processed.txt\"\n",
    "dataset_name = \"rockyou\"\n",
    "\n",
    "# filtered_lines, charmap, inv_charmap = load_dataset(path)\n",
    "# dump_txt_to_pickle(path, dataset_name, test_size=0.1)\n",
    "\n",
    "train_lines, test_lines, charmap, inv_charmap = load_data_from_pickle(dataset_name, train_data=True, test_data=True)\n",
    "rockyou_data = pd.Series(translate(train_lines, inv_charmap) + translate(test_lines, inv_charmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:42.106562\n"
     ]
    }
   ],
   "source": [
    "t = datetime.datetime.now()\n",
    "preds_mask = unique_predictions.isin(rockyou_data)\n",
    "matched_preds = unique_predictions[preds_mask]\n",
    "test_matched_mask = rockyou_data.isin(matched_preds)\n",
    "proportion_of_test_set_that_matched = test_matched_mask.mean()\n",
    "print(datetime.datetime.now() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05135080514648251"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_of_test_set_that_matched"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
